{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_unixtime, avg, count\n",
    "\n",
    "# -----------------------\n",
    "# 1. Inicializar a Spark Session\n",
    "# -----------------------\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL Pipeline - Bronze to Silver to Gold\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configuração das credenciais AWS\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"YOUR_ACCESS_KEY\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", \"YOUR_SECRET_KEY\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\")\n",
    "\n",
    "# -----------------------\n",
    "# 2. Ler os Dados Brutos - Camada Bronze\n",
    "# -----------------------\n",
    "bronze_path = \"s3a://my-bucket-jp-01/raw-data/ipca/kafka/\"\n",
    "\n",
    "# Ler os dados brutos do S3 (formato JSON)\n",
    "df_bronze = spark.read.json(bronze_path)\n",
    "\n",
    "# Visualizar os dados brutos\n",
    "print(\"Dados Brutos (Bronze):\")\n",
    "df_bronze.show(truncate=False)\n",
    "\n",
    "# -----------------------\n",
    "# 3. Tratamento dos Dados - Camada Silver\n",
    "# -----------------------\n",
    "# Remover duplicações e converter timestamps para datas legíveis\n",
    "df_silver = df_bronze.dropDuplicates()\n",
    "\n",
    "# Tratar timestamps e converter para formato legível\n",
    "df_silver = df_silver.withColumn(\"Data_Vencimento\", from_unixtime(col(\"Data_Vencimento\") / 1000, \"yyyy-MM-dd\")) \\\n",
    "    .withColumn(\"Data_Base\", from_unixtime(col(\"Data_Base\") / 1000, \"yyyy-MM-dd\")) \\\n",
    "    .withColumn(\"dt_update\", from_unixtime(col(\"dt_update\") / 1000, \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "# Tratar valores nulos\n",
    "df_silver = df_silver.fillna({\n",
    "    \"PUCompraManha\": 0,\n",
    "    \"PUVendaManha\": 0,\n",
    "    \"PUBaseManha\": 0\n",
    "})\n",
    "\n",
    "# Visualizar os dados transformados\n",
    "print(\"Dados Transformados (Silver):\")\n",
    "df_silver.show(truncate=False)\n",
    "\n",
    "# Salvar os dados limpos no S3 em formato Parquet\n",
    "silver_path = \"s3a://my-bucket-jp-01/processed-data/ipca/silver/\"\n",
    "df_silver.write.mode(\"overwrite\").parquet(silver_path)\n",
    "\n",
    "# -----------------------\n",
    "# 4. Agregação e Métricas - Camada Gold\n",
    "# -----------------------\n",
    "# Calcular métricas agregadas\n",
    "df_gold = df_silver.groupBy(\"Tipo\").agg(\n",
    "    avg(\"PUCompraManha\").alias(\"Media_PUCompraManha\"),\n",
    "    avg(\"PUVendaManha\").alias(\"Media_PUVendaManha\"),\n",
    "    count(\"*\").alias(\"Total_Registros\")\n",
    ")\n",
    "\n",
    "# Visualizar as métricas agregadas\n",
    "print(\"Dados Agregados (Gold):\")\n",
    "df_gold.show(truncate=False)\n",
    "\n",
    "# Salvar os dados agregados no S3 em formato Parquet\n",
    "gold_path = \"s3a://my-bucket-jp-01/analytics/ipca/gold/\"\n",
    "df_gold.write.mode(\"overwrite\").parquet(gold_path)\n",
    "\n",
    "# -----------------------\n",
    "# 5. Encerrar a Spark Session\n",
    "# -----------------------\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
